{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import json\n",
    "from os import getenv\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "from openai import OpenAI\n",
    "\n",
    "# Set the base path\n",
    "base_path = Path(\"../../\")  # One level up from the current working directory\n",
    "\n",
    "# Add the src/ directory to sys.path using base_path\n",
    "sys.path.append(str((base_path / \"src\").resolve()))\n",
    "\n",
    "from tools.python_math_executor import (\n",
    "    PYTHON_MATH_EXECUTION_TOOL,\n",
    "    execute_python\n",
    ")\n",
    "from tool_calling import run_tool_call_loop\n",
    "from save_outputs import save_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(\n",
    "    base_url=\"https://openrouter.ai/api/v1\",\n",
    "    api_key=getenv(\"OPENROUTER_API_KEY\")\n",
    ")\n",
    "\n",
    "# Messages\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Calculate the probability using Bayes' theorem:\\n\"\n",
    "                                \"P(A) = 0.01\\n\"\n",
    "                                \"P(B|A) = 0.9\\n\"\n",
    "                                \"P(B) = 0.05\"}\n",
    "]\n",
    "\n",
    "# Tool registration\n",
    "tools = [\n",
    "    PYTHON_MATH_EXECUTION_TOOL\n",
    "]\n",
    "\n",
    "TOOL_MAPPING = {\n",
    "    \"execute_python\": execute_python\n",
    "}\n",
    "\n",
    "MODEL = \"google/gemini-2.5-pro-preview\"\n",
    "\n",
    "timestamp = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\") # To allow for multiple runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Iteration 1 ---\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'SequenceNotStr' from 'openai._types' (/home/bmihaljevic/repos/code-projects/aily/probabilistic-reasoning-llms/.venv/lib/python3.12/site-packages/openai/_types.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m response, updated_messages = \u001b[43mrun_tool_call_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      2\u001b[39m \u001b[43m    \u001b[49m\u001b[43mopenai_client\u001b[49m\u001b[43m=\u001b[49m\u001b[43mclient\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mMODEL\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtool_mapping\u001b[49m\u001b[43m=\u001b[49m\u001b[43mTOOL_MAPPING\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[32m      8\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/repos/code-projects/aily/probabilistic-reasoning-llms/src/tool_calling.py:40\u001b[39m, in \u001b[36mrun_tool_call_loop\u001b[39m\u001b[34m(openai_client, model, tools, messages, tool_mapping, max_iterations, verbose)\u001b[39m\n\u001b[32m     37\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m verbose:\n\u001b[32m     38\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m--- Iteration \u001b[39m\u001b[38;5;132;01m{\u001b[39;00miteration\u001b[38;5;250m \u001b[39m+\u001b[38;5;250m \u001b[39m\u001b[32m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m ---\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m40\u001b[39m response = \u001b[43mopenai_client\u001b[49m\u001b[43m.\u001b[49m\u001b[43mchat\u001b[49m.completions.create(\n\u001b[32m     41\u001b[39m     model=model,\n\u001b[32m     42\u001b[39m     tools=tools,\n\u001b[32m     43\u001b[39m     messages=messages\n\u001b[32m     44\u001b[39m )\n\u001b[32m     46\u001b[39m msg = response.choices[\u001b[32m0\u001b[39m].message\n\u001b[32m     47\u001b[39m messages.append(msg.model_dump())\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/uv/python/cpython-3.12.3-linux-x86_64-gnu/lib/python3.12/functools.py:995\u001b[39m, in \u001b[36mcached_property.__get__\u001b[39m\u001b[34m(self, instance, owner)\u001b[39m\n\u001b[32m    993\u001b[39m val = cache.get(\u001b[38;5;28mself\u001b[39m.attrname, _NOT_FOUND)\n\u001b[32m    994\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m val \u001b[38;5;129;01mis\u001b[39;00m _NOT_FOUND:\n\u001b[32m--> \u001b[39m\u001b[32m995\u001b[39m     val = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43minstance\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    996\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    997\u001b[39m         cache[\u001b[38;5;28mself\u001b[39m.attrname] = val\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/repos/code-projects/aily/probabilistic-reasoning-llms/.venv/lib/python3.12/site-packages/openai/_client.py:177\u001b[39m, in \u001b[36mchat\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    164\u001b[39m     \u001b[38;5;28msuper\u001b[39m().\u001b[34m__init__\u001b[39m(\n\u001b[32m    165\u001b[39m         version=__version__,\n\u001b[32m    166\u001b[39m         base_url=base_url,\n\u001b[32m   (...)\u001b[39m\u001b[32m    172\u001b[39m         _strict_response_validation=_strict_response_validation,\n\u001b[32m    173\u001b[39m     )\n\u001b[32m    175\u001b[39m     \u001b[38;5;28mself\u001b[39m._default_stream_cls = Stream\n\u001b[32m--> \u001b[39m\u001b[32m177\u001b[39m \u001b[38;5;129m@cached_property\u001b[39m\n\u001b[32m    178\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcompletions\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> Completions:\n\u001b[32m    179\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mresources\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcompletions\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Completions\n\u001b[32m    181\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m Completions(\u001b[38;5;28mself\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/repos/code-projects/aily/probabilistic-reasoning-llms/.venv/lib/python3.12/site-packages/openai/resources/__init__.py:3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mbeta\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m      4\u001b[39m     Beta,\n\u001b[32m      5\u001b[39m     AsyncBeta,\n\u001b[32m      6\u001b[39m     BetaWithRawResponse,\n\u001b[32m      7\u001b[39m     AsyncBetaWithRawResponse,\n\u001b[32m      8\u001b[39m     BetaWithStreamingResponse,\n\u001b[32m      9\u001b[39m     AsyncBetaWithStreamingResponse,\n\u001b[32m     10\u001b[39m )\n\u001b[32m     11\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mchat\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     12\u001b[39m     Chat,\n\u001b[32m     13\u001b[39m     AsyncChat,\n\u001b[32m   (...)\u001b[39m\u001b[32m     17\u001b[39m     AsyncChatWithStreamingResponse,\n\u001b[32m     18\u001b[39m )\n\u001b[32m     19\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01maudio\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     20\u001b[39m     Audio,\n\u001b[32m     21\u001b[39m     AsyncAudio,\n\u001b[32m   (...)\u001b[39m\u001b[32m     25\u001b[39m     AsyncAudioWithStreamingResponse,\n\u001b[32m     26\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/repos/code-projects/aily/probabilistic-reasoning-llms/.venv/lib/python3.12/site-packages/openai/resources/beta/__init__.py:3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mbeta\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m      4\u001b[39m     Beta,\n\u001b[32m      5\u001b[39m     AsyncBeta,\n\u001b[32m      6\u001b[39m     BetaWithRawResponse,\n\u001b[32m      7\u001b[39m     AsyncBetaWithRawResponse,\n\u001b[32m      8\u001b[39m     BetaWithStreamingResponse,\n\u001b[32m      9\u001b[39m     AsyncBetaWithStreamingResponse,\n\u001b[32m     10\u001b[39m )\n\u001b[32m     11\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mthreads\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     12\u001b[39m     Threads,\n\u001b[32m     13\u001b[39m     AsyncThreads,\n\u001b[32m   (...)\u001b[39m\u001b[32m     17\u001b[39m     AsyncThreadsWithStreamingResponse,\n\u001b[32m     18\u001b[39m )\n\u001b[32m     19\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01massistants\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     20\u001b[39m     Assistants,\n\u001b[32m     21\u001b[39m     AsyncAssistants,\n\u001b[32m   (...)\u001b[39m\u001b[32m     25\u001b[39m     AsyncAssistantsWithStreamingResponse,\n\u001b[32m     26\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/repos/code-projects/aily/probabilistic-reasoning-llms/.venv/lib/python3.12/site-packages/openai/resources/beta/beta.py:23\u001b[39m\n\u001b[32m     14\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_resource\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m SyncAPIResource, AsyncAPIResource\n\u001b[32m     15\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mthreads\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mthreads\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     16\u001b[39m     Threads,\n\u001b[32m     17\u001b[39m     AsyncThreads,\n\u001b[32m   (...)\u001b[39m\u001b[32m     21\u001b[39m     AsyncThreadsWithStreamingResponse,\n\u001b[32m     22\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m23\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mresources\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mchat\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Chat, AsyncChat\n\u001b[32m     24\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mrealtime\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mrealtime\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     25\u001b[39m     Realtime,\n\u001b[32m     26\u001b[39m     AsyncRealtime,\n\u001b[32m     27\u001b[39m )\n\u001b[32m     29\u001b[39m __all__ = [\u001b[33m\"\u001b[39m\u001b[33mBeta\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mAsyncBeta\u001b[39m\u001b[33m\"\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/repos/code-projects/aily/probabilistic-reasoning-llms/.venv/lib/python3.12/site-packages/openai/resources/chat/__init__.py:3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mchat\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m      4\u001b[39m     Chat,\n\u001b[32m      5\u001b[39m     AsyncChat,\n\u001b[32m      6\u001b[39m     ChatWithRawResponse,\n\u001b[32m      7\u001b[39m     AsyncChatWithRawResponse,\n\u001b[32m      8\u001b[39m     ChatWithStreamingResponse,\n\u001b[32m      9\u001b[39m     AsyncChatWithStreamingResponse,\n\u001b[32m     10\u001b[39m )\n\u001b[32m     11\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcompletions\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     12\u001b[39m     Completions,\n\u001b[32m     13\u001b[39m     AsyncCompletions,\n\u001b[32m   (...)\u001b[39m\u001b[32m     17\u001b[39m     AsyncCompletionsWithStreamingResponse,\n\u001b[32m     18\u001b[39m )\n\u001b[32m     20\u001b[39m __all__ = [\n\u001b[32m     21\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mCompletions\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     22\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mAsyncCompletions\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m     32\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mAsyncChatWithStreamingResponse\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     33\u001b[39m ]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/repos/code-projects/aily/probabilistic-reasoning-llms/.venv/lib/python3.12/site-packages/openai/resources/chat/chat.py:7\u001b[39m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_compat\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m cached_property\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_resource\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m SyncAPIResource, AsyncAPIResource\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcompletions\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcompletions\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m      8\u001b[39m     Completions,\n\u001b[32m      9\u001b[39m     AsyncCompletions,\n\u001b[32m     10\u001b[39m     CompletionsWithRawResponse,\n\u001b[32m     11\u001b[39m     AsyncCompletionsWithRawResponse,\n\u001b[32m     12\u001b[39m     CompletionsWithStreamingResponse,\n\u001b[32m     13\u001b[39m     AsyncCompletionsWithStreamingResponse,\n\u001b[32m     14\u001b[39m )\n\u001b[32m     16\u001b[39m __all__ = [\u001b[33m\"\u001b[39m\u001b[33mChat\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mAsyncChat\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m     19\u001b[39m \u001b[38;5;28;01mclass\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mChat\u001b[39;00m(SyncAPIResource):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/repos/code-projects/aily/probabilistic-reasoning-llms/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/__init__.py:11\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmessages\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m      4\u001b[39m     Messages,\n\u001b[32m      5\u001b[39m     AsyncMessages,\n\u001b[32m   (...)\u001b[39m\u001b[32m      9\u001b[39m     AsyncMessagesWithStreamingResponse,\n\u001b[32m     10\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcompletions\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     12\u001b[39m     Completions,\n\u001b[32m     13\u001b[39m     AsyncCompletions,\n\u001b[32m     14\u001b[39m     CompletionsWithRawResponse,\n\u001b[32m     15\u001b[39m     AsyncCompletionsWithRawResponse,\n\u001b[32m     16\u001b[39m     CompletionsWithStreamingResponse,\n\u001b[32m     17\u001b[39m     AsyncCompletionsWithStreamingResponse,\n\u001b[32m     18\u001b[39m )\n\u001b[32m     20\u001b[39m __all__ = [\n\u001b[32m     21\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mMessages\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     22\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mAsyncMessages\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m     32\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mAsyncCompletionsWithStreamingResponse\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     33\u001b[39m ]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/repos/code-projects/aily/probabilistic-reasoning-llms/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py:22\u001b[39m\n\u001b[32m     13\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _legacy_response\n\u001b[32m     14\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmessages\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     15\u001b[39m     Messages,\n\u001b[32m     16\u001b[39m     AsyncMessages,\n\u001b[32m   (...)\u001b[39m\u001b[32m     20\u001b[39m     AsyncMessagesWithStreamingResponse,\n\u001b[32m     21\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m22\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_types\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m NOT_GIVEN, Body, Query, Headers, NotGiven, SequenceNotStr\n\u001b[32m     23\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_utils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m required_args, maybe_transform, async_maybe_transform\n\u001b[32m     24\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_compat\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m cached_property\n",
      "\u001b[31mImportError\u001b[39m: cannot import name 'SequenceNotStr' from 'openai._types' (/home/bmihaljevic/repos/code-projects/aily/probabilistic-reasoning-llms/.venv/lib/python3.12/site-packages/openai/_types.py)"
     ]
    }
   ],
   "source": [
    "response, updated_messages = run_tool_call_loop(\n",
    "    openai_client=client,\n",
    "    model=MODEL,\n",
    "    tools=tools,\n",
    "    messages=messages,\n",
    "    tool_mapping=TOOL_MAPPING,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Final response saved to: ../../results/tool_calling_python_math/2025-05-18_13-15-25/gpt-4o-mini/final_response.txt\n",
      "✅ Message history saved to: ../../results/tool_calling_python_math/2025-05-18_13-15-25/gpt-4o-mini/message_history.json\n"
     ]
    }
   ],
   "source": [
    "save_output(\n",
    "    response=response,\n",
    "    messages=messages,\n",
    "    base_path=base_path / \"results\" / \"tool_calling_python_math\",\n",
    "    timestamp=timestamp,\n",
    "    dir_name=MODEL\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
